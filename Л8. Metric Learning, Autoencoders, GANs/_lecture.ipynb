{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Metric Learning на примере распознавания лиц, обзор некоторых методов unsupervised learning в DL.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно применять все базовые значения о нейросетях для решения прикладных продвинутых задач?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этого у нас все задачи имели вид **Supervised Learning** (обучение с учителем).\n",
    "\n",
    "Мы поговорим про задачи **Metric Learning** и **Unsupervised Learning**:\n",
    "\n",
    "![alt text](attach1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Learning\n",
    "\n",
    "...на примере задачи распознавания лиц!\n",
    "\n",
    "![alt text](attach2.png)\n",
    "\n",
    "Наши задачи:\n",
    "\n",
    "1. Кто из людей в трнировочных данных изображён на новом фото? *(сомнительно, но окЭй)*\n",
    "\n",
    "2. На двух новых фото один и тот же человек или нет? *(???)*\n",
    "\n",
    "3. К этем двум дано ещё одно фото нового человека. Изображён ли он на ещё одном фото? *(????)*\n",
    "\n",
    "С нашими текущими инструментами решить такие задачи было бы очень проблематично..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки предпоследнего слоя (Embedding)\n",
    "\n",
    "Давайте посмотрим на самый последний слой перед выходом. Активации нейронов на этом слои, по сути, полностью задают, что сеть \"знает\" про эту картинку (последний слой — линейный классификатор в линейном пр-ве), на примере AlexNet '12:\n",
    "\n",
    "![alt text](attach3.png)\n",
    "\n",
    "Вектора этого предпоследнего слоя обладают интересными свойствами, как бы суммиризируя \"внутреение представления\" о классах в виде векторов в векторном пространстве (где точки данных одного класса расположены (по линейному или косинусному расстоянию) близко, а разных классов — далеко).\n",
    "\n",
    "![alt text](attach4.png)\n",
    "\n",
    "Такая получающаяся точка в линейном пространстве называется **эмбеддингом**, а процесс преобразования класса в точку линейного пространства... тоже **эмбеддигом** (хехе)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как применить этот концепт на практике?\n",
    "\n",
    "Мы хотим, чтобы у разных людей, не смотря на похожие позы и освещение, векторное расстояние было большим, а у одних и тех же — маленьким.\n",
    "\n",
    "![alt text](attach5.png)\n",
    "\n",
    "Это позволило бы нам существенно упростить решение поставленных задач!\n",
    "\n",
    "1. Кто из людей в трнировочных данных изображён на новом фото?\n",
    "    \n",
    "— Просто K-nearest Neighboor\n",
    "\n",
    "2. На двух новых фото один и тот же человек или нет? *(???)*\n",
    "\n",
    "— Просто отсечка по расстоянию\n",
    "\n",
    "3. К этем двум дано ещё одно фото нового человека. Изображён ли он на ещё одном фото?\n",
    "\n",
    "— Добавить новые точки, снова KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но как такую модель получить (или, точнее, натренировать)?\n",
    "\n",
    "### Triplet Loss\n",
    "\n",
    "![alt text](attach6.png)\n",
    "\n",
    "1. Запускаем батч примеров, проводим через конволюционную сеть\n",
    "\n",
    "2. Нормализируем выход (L2), получаем эмбеддинг (например, вектор размера 512)\n",
    "\n",
    "3. Этот эмбеддинг даём специальному **Triplet Loss**\n",
    "\n",
    "**Что это такое?** — мы подготавливаем и берём тройки фотографий, на двух из которых одинаковый человек (Anchor, Positive), а на третьей (Negative) — другой.\n",
    "\n",
    "Мы хотим, чтобы расстояние ежду Anchor и Positive было существенно меньше, чем ежду Anchor и Negative:\n",
    "\n",
    "![alt text](attach8.png)\n",
    "\n",
    "Такой (или похожий) подход, например, применяется в Google Lens (и других современных поисковиках по каритнкам), где на все картинки число классов будет слишком велико."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "![alt text](attach9.png)\n",
    "\n",
    "![alt text](attach10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoders\n",
    "\n",
    "Даём сети на вход картинку и на выходе она должан быть максимально похожей на точно такую же.\n",
    "\n",
    "Но, чтобы сделать задачу нетривиальной (т.е. чтобы сетка не могла просо взять картинку с входа и дать на выход), один из слоёв мы делаем таким, чтобы всю информацию о картинке в него нельзя было записать (**bottleneck**) — в надежде на то, что скть научится \"сжимать\" информацию со входной картинке так, чтобы затем максимально эффективно \"разжать\" её, т.е. максимально эффективно восстановить картинку по ограниченнму набору информации.\n",
    "\n",
    "![alt text](attach11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](attach12.png)\n",
    "\n",
    "### Variational AutoEncoder (VAE)\n",
    "\n",
    "![alt text](attach13.png)\n",
    "\n",
    "### Всякие интересные приколы с автоэнкодером \n",
    "\n",
    "Интерполяции:\n",
    "\n",
    "![alt text](attach14.png)\n",
    "\n",
    "Операции с latent space:\n",
    "\n",
    "![alt text](attach15.png)\n",
    "\n",
    "Проблема в том, что из-за такого усреднения у нас получаются чочень очень размытые картинки (особенно по заднему фону заметно). Но есть и другой подход:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GANs)\n",
    "\n",
    "*генеративно-состязательные сети*\n",
    "\n",
    "![alt text](attach16.png)\n",
    "\n",
    "Стравливаем друг на друга две нейронки — генератор и дискриминатор:\n",
    "\n",
    "![alt text](attach17.png)\n",
    "\n",
    "**Цель дискриминатора** — отличить реальную картинку от сгенерированной; **Цель генератора** — обмануть дискриминатор, научившись создавать максимально похожие на реалиные картинки.\n",
    "\n",
    "https://www.youtube.com/live/ajEQ10s8XRg?t=3700 *(да, я за\\*\\*ался, вопросы?)*\n",
    "\n",
    "![alt text](attach18.png)\n",
    "\n",
    "Если вкратце, идея в том, что изначально генератор инициализирован шумом, т.е. на основе случайной точки он просто создаёт шум. Естественно, дискриминатор с лёгкостью обучается их отличать от реальных картинок через несколько итераций.\n",
    "\n",
    "После этого мы, на основе замороженных весов дискриминатора, обновляем веса генератора (т.е. делает правку на ошибки по признакам, на которые дискриминатор опирался при классификации картинок на реальные и фейковые).\n",
    "\n",
    "Таким образом, генератор и дискриминатор как бы играют друг с другом в игру, чтобы минимизировать максимизации фукнции, обведённой оранжевым прямоугольником.\n",
    "\n",
    "![alt text](attach20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интересные приколы\n",
    "\n",
    "Интерполяции:\n",
    "\n",
    "![alt text](attach21.png)\n",
    "\n",
    "Арифметика в Latent Space:\n",
    "\n",
    "![alt text](attach22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### До чего дошёл* прогресс...\n",
    "\n",
    "\\*по состоянию на 2019 год\n",
    "\n",
    "### ZooGAN — подборка GAN-ов, последний раз обновлялась в октябре 2018.\n",
    "\n",
    "https://github.com/hindupuravinash/the-gan-zoo\n",
    "\n",
    "### StyleGAN 2018\n",
    "\n",
    "Самая крутая на то время модель (на тов ремя — очень неплохо). На её основе до сих пор работает сайт ThisPersonDoesNotExist.Com =)\n",
    "\n",
    "![alt text](attach24.png)\n",
    "\n",
    "### Pix2Pix '17\n",
    "\n",
    "![alt text](attach25.png)\n",
    "\n",
    "### Rendering with GANs\n",
    "\n",
    "Рендеринг картинки (справа) на основе сегментационной маски (слева оригинал, слева снизу маска)\n",
    "\n",
    "![alt text](attach26.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *произошёл микросос бимбус...*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
